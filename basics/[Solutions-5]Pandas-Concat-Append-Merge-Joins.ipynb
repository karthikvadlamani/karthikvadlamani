{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[Solutions-5]Pandas-Concat-Append-Merge-Joins.ipynb","provenance":[{"file_id":"1wn5rrtTNK6hWVovuS2YhQUxvwPSND-FE","timestamp":1564859061589}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wb0PmFpoG9ay"},"source":["![sslogo](https://github.com/stratascratch/stratascratch.github.io/raw/master/assets/sslogo.jpg)"]},{"cell_type":"markdown","metadata":{"id":"u4FCtjigWA6-"},"source":["#### The make_df helper function will be used to generate DataFrames"]},{"cell_type":"code","metadata":{"id":"W1kGox_iWA6_"},"source":["def make_df(cols, ind):\n","    \"\"\"Quickly make a DataFrame\"\"\"\n","    data = {c: [str(c) + str(i) for i in ind]\n","            for c in cols}\n","    return pd.DataFrame(data, ind)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kdg-YPf3WA7D"},"source":["#### For results requiring multiple tables, use the display class to format your results"]},{"cell_type":"code","metadata":{"id":"bd-xl9okWA7E"},"source":["class display(object):\n","    \"\"\"Display HTML representation of multiple objects\"\"\"\n","    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n","    </div>\"\"\"\n","    def __init__(self, *args):\n","        self.args = args\n","        \n","    def _repr_html_(self):\n","        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n","                         for a in self.args)\n","    \n","    def __repr__(self):\n","        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n","                           for a in self.args)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AgHcQ_3DWA65"},"source":["# Combining Datasets: Concat and Append"]},{"cell_type":"markdown","metadata":{"id":"JwQVBoOdWA7P"},"source":["## Simple Concatenation with ``pd.concat``"]},{"cell_type":"code","metadata":{"id":"LdhJnjzLFL8p"},"source":["ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n","ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"razP0rIpFL8r"},"source":["#### Concatenate ser1 and ser2"]},{"cell_type":"code","metadata":{"id":"e405KLHlWA7R","outputId":"c2cde80b-1075-479b-8813-6bf5edc6d878"},"source":["pd.concat([ser1, ser2])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    A\n","2    B\n","3    C\n","4    D\n","5    E\n","6    F\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"s7A0SxZNWA7V","outputId":"c876c290-7b13-4159-f709-a55454c6612f"},"source":["df1 = make_df('AB', [1, 2])\n","df2 = make_df('AB', [3, 4])\n","df3 = make_df('CD', [5, 6])\n","\n","display('df1', 'df2', 'df3')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>df1</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>A1</td>\n","      <td>B1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A2</td>\n","      <td>B2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>df2</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>A3</td>\n","      <td>B3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A4</td>\n","      <td>B4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>df3</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>C5</td>\n","      <td>D5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>C6</td>\n","      <td>D6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["df1\n","    A   B\n","1  A1  B1\n","2  A2  B2\n","\n","df2\n","    A   B\n","3  A3  B3\n","4  A4  B4\n","\n","df3\n","    C   D\n","5  C5  D5\n","6  C6  D6"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"markdown","metadata":{"id":"IJjphCyXFL8x"},"source":["#### Concatenate df1's and df2's rows"]},{"cell_type":"code","metadata":{"id":"CgONZTjFFL8y","outputId":"2fc7041e-6ff4-48f5-8111-b12bcb72bc5f"},"source":["pd.concat([df1, df2])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>A1</td>\n","      <td>B1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A2</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A3</td>\n","      <td>B3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A4</td>\n","      <td>B4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    A   B\n","1  A1  B1\n","2  A2  B2\n","3  A3  B3\n","4  A4  B4"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"HWypK6vnWA7Y"},"source":["#### Concatenate df1's and df2's columns"]},{"cell_type":"code","metadata":{"id":"hnculJknWA7Y","outputId":"83bb455d-22df-427f-ef51-c160750645ea"},"source":["pd.concat([df2, df3], axis=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>A3</td>\n","      <td>B3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A4</td>\n","      <td>B4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>C5</td>\n","      <td>D5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>C6</td>\n","      <td>D6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     A    B    C    D\n","3   A3   B3  NaN  NaN\n","4   A4   B4  NaN  NaN\n","5  NaN  NaN   C5   D5\n","6  NaN  NaN   C6   D6"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"YoPwwLBtWA7c"},"source":["### Duplicate indices"]},{"cell_type":"markdown","metadata":{"id":"j3qKE87iFL99"},"source":["#### The following concatenation createst a table with repeated indexes. This is an issue that should always be avoided!"]},{"cell_type":"code","metadata":{"id":"jG2hqK1CWA7d","outputId":"e0a449f2-0964-44dd-edd7-4e2afd092faf"},"source":["x = make_df('AB', [0, 1])\n","y = make_df('AB', [2, 3])\n","y.index = x.index\n","display('x', 'y', 'pd.concat([x, y])')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>x</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A0</td>\n","      <td>B0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A1</td>\n","      <td>B1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>y</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A2</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A3</td>\n","      <td>B3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>pd.concat([x, y])</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A0</td>\n","      <td>B0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A1</td>\n","      <td>B1</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>A2</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A3</td>\n","      <td>B3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["x\n","    A   B\n","0  A0  B0\n","1  A1  B1\n","\n","y\n","    A   B\n","0  A2  B2\n","1  A3  B3\n","\n","pd.concat([x, y])\n","    A   B\n","0  A0  B0\n","1  A1  B1\n","0  A2  B2\n","1  A3  B3"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"SY3dbHSrWA7h"},"source":["#### Cause the concatenation of x and y to throw an error with the verify_integrity parameter and catch the error. Print a fitting error message"]},{"cell_type":"code","metadata":{"id":"nRU5sD_GWA7i","outputId":"6a48f845-ea81-4585-9ac0-b45142afa001"},"source":["try:\n","    pd.concat([x, y], verify_integrity=True)\n","except ValueError as e:\n","    print(\"ValueError:\", e)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ValueError: Indexes have overlapping values: Int64Index([0, 1], dtype='int64')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MJ4mIv0AWA7q"},"source":["#### Concatenate x and y. Avoid an overlapping index error by creating a multiindex key"]},{"cell_type":"code","metadata":{"id":"YIOQ1GLoWA7q","outputId":"878d0378-3877-40d5-f675-77b79c68783c"},"source":["pd.concat([x, y], keys=['x', 'y'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">x</th>\n","      <th>0</th>\n","      <td>A0</td>\n","      <td>B0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A1</td>\n","      <td>B1</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">y</th>\n","      <th>0</th>\n","      <td>A2</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A3</td>\n","      <td>B3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      A   B\n","x 0  A0  B0\n","  1  A1  B1\n","y 0  A2  B2\n","  1  A3  B3"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"9R5pF9DPWA7l"},"source":["#### Concatenate x and y. Avoid an overlapping index error by ignoring the original indexes"]},{"cell_type":"code","metadata":{"id":"QG_LG1KlWA7m","outputId":"5ef618c0-662b-4287-f099-cb401e84806c"},"source":["pd.concat([x, y], ignore_index=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A0</td>\n","      <td>B0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A1</td>\n","      <td>B1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A2</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A3</td>\n","      <td>B3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    A   B\n","0  A0  B0\n","1  A1  B1\n","2  A2  B2\n","3  A3  B3"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"yjb4iO7iWA7v"},"source":["### Concatenation with joins"]},{"cell_type":"markdown","metadata":{"id":"N7CT6W4FFL-L"},"source":["#### The statements below show the default behavior of pd.concat on DataFrames. What type of join is the default? Add a join parameter with the default join type"]},{"cell_type":"code","metadata":{"id":"yMjBJu0BWA7w","outputId":"d4dd9c59-f5a1-44a4-839b-52442307a28f"},"source":["df5 = make_df('ABC', [1, 2]) \n","df6 = make_df('BCD', [3, 4])\n","display('df5', 'df6', 'pd.concat([df5, df6], sort=False, join=\"outer\")')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>df5</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>A1</td>\n","      <td>B1</td>\n","      <td>C1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A2</td>\n","      <td>B2</td>\n","      <td>C2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>df6</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>B3</td>\n","      <td>C3</td>\n","      <td>D3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>B4</td>\n","      <td>C4</td>\n","      <td>D4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>pd.concat([df5, df6], sort=False, join=\"outer\")</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>A1</td>\n","      <td>B1</td>\n","      <td>C1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A2</td>\n","      <td>B2</td>\n","      <td>C2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>B3</td>\n","      <td>C3</td>\n","      <td>D3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>B4</td>\n","      <td>C4</td>\n","      <td>D4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["df5\n","    A   B   C\n","1  A1  B1  C1\n","2  A2  B2  C2\n","\n","df6\n","    B   C   D\n","3  B3  C3  D3\n","4  B4  C4  D4\n","\n","pd.concat([df5, df6], sort=False, join=\"outer\")\n","     A   B   C    D\n","1   A1  B1  C1  NaN\n","2   A2  B2  C2  NaN\n","3  NaN  B3  C3   D3\n","4  NaN  B4  C4   D4"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"-hn0iIV8FL-P"},"source":["#### Perform the above concatenation using the append method\n","\n","Remember: the append method is the specific case (axis=0, join='outer') of the concat method, the parameters cannot be modified"]},{"cell_type":"code","metadata":{"id":"BCrZLe52WA79","outputId":"fa0e6896-f373-402b-c2ea-10f14424ea64"},"source":["df5.append(df6, sort=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>A1</td>\n","      <td>B1</td>\n","      <td>C1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A2</td>\n","      <td>B2</td>\n","      <td>C2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>B3</td>\n","      <td>C3</td>\n","      <td>D3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>B4</td>\n","      <td>C4</td>\n","      <td>D4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     A   B   C    D\n","1   A1  B1  C1  NaN\n","2   A2  B2  C2  NaN\n","3  NaN  B3  C3   D3\n","4  NaN  B4  C4   D4"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"Z-Rmfo5jWA70"},"source":["#### Concatenate df5 and df6 only keeping the columns from both tables"]},{"cell_type":"code","metadata":{"id":"6cTqgtczWA71","outputId":"3eee4430-7407-4b54-86ac-dd9ab9c93fcc"},"source":["pd.concat([df5, df6], join='inner')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>B</th>\n","      <th>C</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>B1</td>\n","      <td>C1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>B2</td>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>B3</td>\n","      <td>C3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>B4</td>\n","      <td>C4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    B   C\n","1  B1  C1\n","2  B2  C2\n","3  B3  C3\n","4  B4  C4"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"QYxbAdHzW0_1"},"source":["# Combining Datasets: Merge and Join"]},{"cell_type":"markdown","metadata":{"id":"zqF3clIFFL-e"},"source":["#### The worker, title, and bonus tables are from a relational database. "]},{"cell_type":"code","metadata":{"id":"aoTNyXN2FL-f","outputId":"78196dc7-cbb3-49e8-c007-bc9b8131f909"},"source":["#import worker.csv, title.csv, bonus.csv from dataset folder below\n","#https://bit.ly/3gsZdUS\n","\n","worker = pd.read_csv('worker.csv')\n","title = pd.read_csv('title.csv')\n","bonus = pd.read_csv('bonus.csv')\n","\n","#name dataframe with same variable names as below\n","display('worker', 'title', 'bonus')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>worker</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>worker_id</th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>salary</th>\n","      <th>joining_date</th>\n","      <th>department</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Monika</td>\n","      <td>Arora</td>\n","      <td>100000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Niharika</td>\n","      <td>Verma</td>\n","      <td>80000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Vishal</td>\n","      <td>Singhal</td>\n","      <td>300000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Amitah</td>\n","      <td>Singh</td>\n","      <td>500000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>Admin</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Vivek</td>\n","      <td>Bhati</td>\n","      <td>500000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>Vipul</td>\n","      <td>Diwan</td>\n","      <td>200000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Account</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>Satish</td>\n","      <td>Kumar</td>\n","      <td>75000</td>\n","      <td>2014-01-20 9:00:00</td>\n","      <td>Account</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>Geetika</td>\n","      <td>Chauhan</td>\n","      <td>90000</td>\n","      <td>2014-04-11 9:00:00</td>\n","      <td>Admin</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>title</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>worker_ref_id</th>\n","      <th>worker_title</th>\n","      <th>affected_from</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Manager</td>\n","      <td>2016-02-20 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>Manager</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Asst. Manager</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>7</td>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>Lead</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>3</td>\n","      <td>Lead</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>bonus</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>worker_ref_id</th>\n","      <th>bonus_amount</th>\n","      <th>bonus_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>2020-02-16 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>3000</td>\n","      <td>2011-06-16 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>4000</td>\n","      <td>2020-02-16 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>4500</td>\n","      <td>2020-02-16 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>3500</td>\n","      <td>2011-06-16 0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["worker\n","   worker_id first_name last_name  salary        joining_date department\n","0          1     Monika     Arora  100000  2014-02-20 9:00:00         HR\n","1          2   Niharika     Verma   80000  2014-06-11 9:00:00      Admin\n","2          3     Vishal   Singhal  300000  2014-02-20 9:00:00         HR\n","3          4     Amitah     Singh  500000  2014-02-20 9:00:00      Admin\n","4          5      Vivek     Bhati  500000  2014-06-11 9:00:00      Admin\n","5          6      Vipul     Diwan  200000  2014-06-11 9:00:00    Account\n","6          7     Satish     Kumar   75000  2014-01-20 9:00:00    Account\n","7          8    Geetika   Chauhan   90000  2014-04-11 9:00:00      Admin\n","\n","title\n","   worker_ref_id   worker_title       affected_from\n","0              1        Manager  2016-02-20 0:00:00\n","1              2      Executive  2016-06-11 0:00:00\n","2              8      Executive  2016-06-11 0:00:00\n","3              5        Manager  2016-06-11 0:00:00\n","4              4  Asst. Manager  2016-06-11 0:00:00\n","5              7      Executive  2016-06-11 0:00:00\n","6              6           Lead  2016-06-11 0:00:00\n","7              3           Lead  2016-06-11 0:00:00\n","\n","bonus\n","   worker_ref_id  bonus_amount          bonus_date\n","0              1          5000  2020-02-16 0:00:00\n","1              2          3000  2011-06-16 0:00:00\n","2              3          4000  2020-02-16 0:00:00\n","3              1          4500  2020-02-16 0:00:00\n","4              2          3500  2011-06-16 0:00:00"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"yOsAJdFRFL-h"},"source":["#### The employee DataFrames are part of a seperate relational database"]},{"cell_type":"code","metadata":{"id":"CWW3nCQsFL-h","outputId":"daf1d520-a99b-4c4e-d4cd-1ad42118d7aa"},"source":["employee_group = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n","                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n","employee_hire_date = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n","                    'hire_date': [2004, 2008, 2012, 2014]})\n","display('employee_group', 'employee_hire_date')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>employee_group</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>employee</th>\n","      <th>group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>Accounting</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>Engineering</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>Engineering</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>HR</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>employee_hire_date</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>employee</th>\n","      <th>hire_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Lisa</td>\n","      <td>2004</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bob</td>\n","      <td>2008</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Jake</td>\n","      <td>2012</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>2014</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["employee_group\n","  employee        group\n","0      Bob   Accounting\n","1     Jake  Engineering\n","2     Lisa  Engineering\n","3      Sue           HR\n","\n","employee_hire_date\n","  employee  hire_date\n","0     Lisa       2004\n","1      Bob       2008\n","2     Jake       2012\n","3      Sue       2014"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"4cG59O5RW0_6"},"source":["### One-to-one joins"]},{"cell_type":"markdown","metadata":{"id":"xcks7l-PFL-j"},"source":["#### Merge the employee_group and employee_hire_data tables"]},{"cell_type":"code","metadata":{"id":"Zlxo93t4FL-k","outputId":"01811545-0496-4905-b2a3-72f59de379a3"},"source":["pd.merge(employee_group, employee_hire_date)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>employee</th>\n","      <th>group</th>\n","      <th>hire_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>Accounting</td>\n","      <td>2008</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>Engineering</td>\n","      <td>2012</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>Engineering</td>\n","      <td>2004</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>HR</td>\n","      <td>2014</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  employee        group  hire_date\n","0      Bob   Accounting       2008\n","1     Jake  Engineering       2012\n","2     Lisa  Engineering       2004\n","3      Sue           HR       2014"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"SbKllxdOFL-p"},"source":["#### Merge the worker and title tables"]},{"cell_type":"code","metadata":{"id":"zw5POIrSFL-q","outputId":"bc228228-bd2e-4aa6-c8e9-46b449af633c"},"source":["pd.merge(worker, title, left_on=\"worker_id\", right_on=\"worker_ref_id\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>worker_id</th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>salary</th>\n","      <th>joining_date</th>\n","      <th>department</th>\n","      <th>worker_ref_id</th>\n","      <th>worker_title</th>\n","      <th>affected_from</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Monika</td>\n","      <td>Arora</td>\n","      <td>100000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","      <td>1</td>\n","      <td>Manager</td>\n","      <td>2016-02-20 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Niharika</td>\n","      <td>Verma</td>\n","      <td>80000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","      <td>2</td>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Vishal</td>\n","      <td>Singhal</td>\n","      <td>300000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","      <td>3</td>\n","      <td>Lead</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Amitah</td>\n","      <td>Singh</td>\n","      <td>500000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>Admin</td>\n","      <td>4</td>\n","      <td>Asst. Manager</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Vivek</td>\n","      <td>Bhati</td>\n","      <td>500000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","      <td>5</td>\n","      <td>Manager</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>Vipul</td>\n","      <td>Diwan</td>\n","      <td>200000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Account</td>\n","      <td>6</td>\n","      <td>Lead</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>Satish</td>\n","      <td>Kumar</td>\n","      <td>75000</td>\n","      <td>2014-01-20 9:00:00</td>\n","      <td>Account</td>\n","      <td>7</td>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>Geetika</td>\n","      <td>Chauhan</td>\n","      <td>90000</td>\n","      <td>2014-04-11 9:00:00</td>\n","      <td>Admin</td>\n","      <td>8</td>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   worker_id first_name last_name  salary        joining_date department  \\\n","0          1     Monika     Arora  100000  2014-02-20 9:00:00         HR   \n","1          2   Niharika     Verma   80000  2014-06-11 9:00:00      Admin   \n","2          3     Vishal   Singhal  300000  2014-02-20 9:00:00         HR   \n","3          4     Amitah     Singh  500000  2014-02-20 9:00:00      Admin   \n","4          5      Vivek     Bhati  500000  2014-06-11 9:00:00      Admin   \n","5          6      Vipul     Diwan  200000  2014-06-11 9:00:00    Account   \n","6          7     Satish     Kumar   75000  2014-01-20 9:00:00    Account   \n","7          8    Geetika   Chauhan   90000  2014-04-11 9:00:00      Admin   \n","\n","   worker_ref_id   worker_title       affected_from  \n","0              1        Manager  2016-02-20 0:00:00  \n","1              2      Executive  2016-06-11 0:00:00  \n","2              3           Lead  2016-06-11 0:00:00  \n","3              4  Asst. Manager  2016-06-11 0:00:00  \n","4              5        Manager  2016-06-11 0:00:00  \n","5              6           Lead  2016-06-11 0:00:00  \n","6              7      Executive  2016-06-11 0:00:00  \n","7              8      Executive  2016-06-11 0:00:00  "]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"zrseA2w6W1AC"},"source":["### Many-to-one joins"]},{"cell_type":"code","metadata":{"id":"S3iQpFOiW1AD","outputId":"5acf3dd3-fb6c-49af-bd9e-8cb1ab12bdba"},"source":["employee_supervisor = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n","                                    'supervisor': ['Carly', 'Guido', 'Steve']})\n","employee_supervisor"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>group</th>\n","      <th>supervisor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Accounting</td>\n","      <td>Carly</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Engineering</td>\n","      <td>Guido</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>HR</td>\n","      <td>Steve</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         group supervisor\n","0   Accounting      Carly\n","1  Engineering      Guido\n","2           HR      Steve"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"FL0RFZ85FL-v"},"source":["#### Merge the employee_group and employee_supervisor tables"]},{"cell_type":"code","metadata":{"id":"MLDbfpTQFL-w","outputId":"8c00c2eb-aaf7-425f-d1d9-53275daf1c6d"},"source":["pd.merge(employee_group, employee_supervisor)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>employee</th>\n","      <th>group</th>\n","      <th>supervisor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>Accounting</td>\n","      <td>Carly</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>Engineering</td>\n","      <td>Guido</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>Engineering</td>\n","      <td>Guido</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>HR</td>\n","      <td>Steve</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  employee        group supervisor\n","0      Bob   Accounting      Carly\n","1     Jake  Engineering      Guido\n","2     Lisa  Engineering      Guido\n","3      Sue           HR      Steve"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"IjIWPJ7GFL-y"},"source":["#### Merge the worker and bonus tables."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"NuPHO4bVFL-z","outputId":"c2703f44-c896-412d-b796-09cb58f06fb0"},"source":["pd.merge(worker, bonus, left_on=\"worker_id\", right_on=\"worker_ref_id\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>worker_id</th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>salary</th>\n","      <th>joining_date</th>\n","      <th>department</th>\n","      <th>worker_ref_id</th>\n","      <th>bonus_amount</th>\n","      <th>bonus_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Monika</td>\n","      <td>Arora</td>\n","      <td>100000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>2020-02-16 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Monika</td>\n","      <td>Arora</td>\n","      <td>100000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","      <td>1</td>\n","      <td>4500</td>\n","      <td>2020-02-16 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Niharika</td>\n","      <td>Verma</td>\n","      <td>80000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","      <td>2</td>\n","      <td>3000</td>\n","      <td>2011-06-16 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>Niharika</td>\n","      <td>Verma</td>\n","      <td>80000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","      <td>2</td>\n","      <td>3500</td>\n","      <td>2011-06-16 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>Vishal</td>\n","      <td>Singhal</td>\n","      <td>300000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","      <td>3</td>\n","      <td>4000</td>\n","      <td>2020-02-16 0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   worker_id first_name last_name  salary        joining_date department  \\\n","0          1     Monika     Arora  100000  2014-02-20 9:00:00         HR   \n","1          1     Monika     Arora  100000  2014-02-20 9:00:00         HR   \n","2          2   Niharika     Verma   80000  2014-06-11 9:00:00      Admin   \n","3          2   Niharika     Verma   80000  2014-06-11 9:00:00      Admin   \n","4          3     Vishal   Singhal  300000  2014-02-20 9:00:00         HR   \n","\n","   worker_ref_id  bonus_amount          bonus_date  \n","0              1          5000  2020-02-16 0:00:00  \n","1              1          4500  2020-02-16 0:00:00  \n","2              2          3000  2011-06-16 0:00:00  \n","3              2          3500  2011-06-16 0:00:00  \n","4              3          4000  2020-02-16 0:00:00  "]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"FaUPywkLW1AF"},"source":["### Many-to-many joins"]},{"cell_type":"code","metadata":{"id":"-EJzUDd9W1AG","outputId":"355dbdab-40f8-4d02-f8a4-7c634f711449"},"source":["employee_skills = pd.DataFrame({'group': ['Accounting', 'Accounting',\n","                                  'Engineering', 'Engineering', 'HR', 'HR'],\n","                                'skills': ['math', 'spreadsheets', 'coding', 'linux',\n","                                  'spreadsheets', 'organization']})\n","employee_skills"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>group</th>\n","      <th>skills</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Accounting</td>\n","      <td>math</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Accounting</td>\n","      <td>spreadsheets</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Engineering</td>\n","      <td>coding</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Engineering</td>\n","      <td>linux</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>HR</td>\n","      <td>spreadsheets</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>HR</td>\n","      <td>organization</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         group        skills\n","0   Accounting          math\n","1   Accounting  spreadsheets\n","2  Engineering        coding\n","3  Engineering         linux\n","4           HR  spreadsheets\n","5           HR  organization"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"fPYafVoBFL-3"},"source":["#### Merge the employee_group and employee_skill tables"]},{"cell_type":"code","metadata":{"id":"xHf6rjioFL-4","outputId":"49cad537-03d3-4861-a3bb-516516f3313d"},"source":["pd.merge(employee_group, employee_skills)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>employee</th>\n","      <th>group</th>\n","      <th>skills</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>Accounting</td>\n","      <td>math</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bob</td>\n","      <td>Accounting</td>\n","      <td>spreadsheets</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Jake</td>\n","      <td>Engineering</td>\n","      <td>coding</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Jake</td>\n","      <td>Engineering</td>\n","      <td>linux</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Lisa</td>\n","      <td>Engineering</td>\n","      <td>coding</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Lisa</td>\n","      <td>Engineering</td>\n","      <td>linux</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Sue</td>\n","      <td>HR</td>\n","      <td>spreadsheets</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Sue</td>\n","      <td>HR</td>\n","      <td>organization</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  employee        group        skills\n","0      Bob   Accounting          math\n","1      Bob   Accounting  spreadsheets\n","2     Jake  Engineering        coding\n","3     Jake  Engineering         linux\n","4     Lisa  Engineering        coding\n","5     Lisa  Engineering         linux\n","6      Sue           HR  spreadsheets\n","7      Sue           HR  organization"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"zdhx59WSW1AK"},"source":["## Specification of the Merge Key"]},{"cell_type":"code","metadata":{"id":"ViNC-XGzW1AP","scrolled":true,"outputId":"8699da49-cc77-4c20-c686-935992b07d44"},"source":["employee_salary = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n","                                'salary': [70000, 80000, 120000, 90000]})\n","employee_salary"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>70000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>80000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>120000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>90000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   name  salary\n","0   Bob   70000\n","1  Jake   80000\n","2  Lisa  120000\n","3   Sue   90000"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"N8mCV73qFL--"},"source":["#### Merge the employee_group and employee_hire_date tables and specify the employee column to join on. Assign the resulting table to employees"]},{"cell_type":"code","metadata":{"id":"w5Omya4TFL--","outputId":"ef40fe0e-08f9-4b09-df1d-d9a197fc7c59"},"source":["employees = pd.merge(employee_group, employee_hire_date, on='employee')\n","employees"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>employee</th>\n","      <th>group</th>\n","      <th>hire_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>Accounting</td>\n","      <td>2008</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>Engineering</td>\n","      <td>2012</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>Engineering</td>\n","      <td>2004</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>HR</td>\n","      <td>2014</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  employee        group  hire_date\n","0      Bob   Accounting       2008\n","1     Jake  Engineering       2012\n","2     Lisa  Engineering       2004\n","3      Sue           HR       2014"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"pLLA1t2xFL_A"},"source":["#### Merge the employees and employee_supervisor tables and specify the group column to join on"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"6Hu783y0FL_B","outputId":"27cf34b4-ce5a-4d71-b5f0-3c343e2707b3"},"source":["pd.merge(employees, employee_supervisor, on='group')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>employee</th>\n","      <th>group</th>\n","      <th>hire_date</th>\n","      <th>supervisor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>Accounting</td>\n","      <td>2008</td>\n","      <td>Carly</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>Engineering</td>\n","      <td>2012</td>\n","      <td>Guido</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>Engineering</td>\n","      <td>2004</td>\n","      <td>Guido</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>HR</td>\n","      <td>2014</td>\n","      <td>Steve</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  employee        group  hire_date supervisor\n","0      Bob   Accounting       2008      Carly\n","1     Jake  Engineering       2012      Guido\n","2     Lisa  Engineering       2004      Guido\n","3      Sue           HR       2014      Steve"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"HGWqIL8sFL_C"},"source":["#### Merge the employees and employee_salary tables"]},{"cell_type":"code","metadata":{"id":"4HuzcRpTFL_E","outputId":"1574887c-40af-40f1-fcbc-2461d3edfdf0"},"source":["pd.merge(employees, employee_salary, left_on=\"employee\", right_on='name')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>employee</th>\n","      <th>group</th>\n","      <th>hire_date</th>\n","      <th>name</th>\n","      <th>salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>Accounting</td>\n","      <td>2008</td>\n","      <td>Bob</td>\n","      <td>70000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>Engineering</td>\n","      <td>2012</td>\n","      <td>Jake</td>\n","      <td>80000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>Engineering</td>\n","      <td>2004</td>\n","      <td>Lisa</td>\n","      <td>120000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>HR</td>\n","      <td>2014</td>\n","      <td>Sue</td>\n","      <td>90000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  employee        group  hire_date  name  salary\n","0      Bob   Accounting       2008   Bob   70000\n","1     Jake  Engineering       2012  Jake   80000\n","2     Lisa  Engineering       2004  Lisa  120000\n","3      Sue           HR       2014   Sue   90000"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"PacxarHuFL_H"},"source":["___"]},{"cell_type":"code","metadata":{"id":"Lb02qUDzFL_H","outputId":"c37ea384-b52b-447a-fdcb-68a159dd9bbd"},"source":["worker_indexed = worker.set_index('worker_id')\n","title_indexed = title.set_index('worker_ref_id')\n","\n","display('worker_indexed', 'title_indexed')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>worker_indexed</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>salary</th>\n","      <th>joining_date</th>\n","      <th>department</th>\n","    </tr>\n","    <tr>\n","      <th>worker_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Monika</td>\n","      <td>Arora</td>\n","      <td>100000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Niharika</td>\n","      <td>Verma</td>\n","      <td>80000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Vishal</td>\n","      <td>Singhal</td>\n","      <td>300000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amitah</td>\n","      <td>Singh</td>\n","      <td>500000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>Admin</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Vivek</td>\n","      <td>Bhati</td>\n","      <td>500000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Vipul</td>\n","      <td>Diwan</td>\n","      <td>200000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Account</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Satish</td>\n","      <td>Kumar</td>\n","      <td>75000</td>\n","      <td>2014-01-20 9:00:00</td>\n","      <td>Account</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Geetika</td>\n","      <td>Chauhan</td>\n","      <td>90000</td>\n","      <td>2014-04-11 9:00:00</td>\n","      <td>Admin</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>title_indexed</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>worker_title</th>\n","      <th>affected_from</th>\n","    </tr>\n","    <tr>\n","      <th>worker_ref_id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Manager</td>\n","      <td>2016-02-20 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Manager</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Asst. Manager</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Lead</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Lead</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["worker_indexed\n","          first_name last_name  salary        joining_date department\n","worker_id                                                            \n","1             Monika     Arora  100000  2014-02-20 9:00:00         HR\n","2           Niharika     Verma   80000  2014-06-11 9:00:00      Admin\n","3             Vishal   Singhal  300000  2014-02-20 9:00:00         HR\n","4             Amitah     Singh  500000  2014-02-20 9:00:00      Admin\n","5              Vivek     Bhati  500000  2014-06-11 9:00:00      Admin\n","6              Vipul     Diwan  200000  2014-06-11 9:00:00    Account\n","7             Satish     Kumar   75000  2014-01-20 9:00:00    Account\n","8            Geetika   Chauhan   90000  2014-04-11 9:00:00      Admin\n","\n","title_indexed\n","                worker_title       affected_from\n","worker_ref_id                                   \n","1                    Manager  2016-02-20 0:00:00\n","2                  Executive  2016-06-11 0:00:00\n","8                  Executive  2016-06-11 0:00:00\n","5                    Manager  2016-06-11 0:00:00\n","4              Asst. Manager  2016-06-11 0:00:00\n","7                  Executive  2016-06-11 0:00:00\n","6                       Lead  2016-06-11 0:00:00\n","3                       Lead  2016-06-11 0:00:00"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"pZUYadLfW1AU","outputId":"8fb41aa8-4461-4277-87e9-4b6d9294b226"},"source":["employee_group_indexed = employee_group.set_index('employee')\n","employee_group_indexed"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>group</th>\n","    </tr>\n","    <tr>\n","      <th>employee</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Bob</th>\n","      <td>Accounting</td>\n","    </tr>\n","    <tr>\n","      <th>Jake</th>\n","      <td>Engineering</td>\n","    </tr>\n","    <tr>\n","      <th>Lisa</th>\n","      <td>Engineering</td>\n","    </tr>\n","    <tr>\n","      <th>Sue</th>\n","      <td>HR</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                group\n","employee             \n","Bob        Accounting\n","Jake      Engineering\n","Lisa      Engineering\n","Sue                HR"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"57KNIyBeFL_M"},"source":["#### Merge the worker_indexed and title_indexed tables"]},{"cell_type":"code","metadata":{"id":"HSWcAeFRFL_N","outputId":"93bf1ec6-5a8f-431f-8b23-a120b9892122"},"source":["pd.merge(worker_indexed, title_indexed, left_index=True, right_index=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>last_name</th>\n","      <th>salary</th>\n","      <th>joining_date</th>\n","      <th>department</th>\n","      <th>worker_title</th>\n","      <th>affected_from</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Monika</td>\n","      <td>Arora</td>\n","      <td>100000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","      <td>Manager</td>\n","      <td>2016-02-20 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Niharika</td>\n","      <td>Verma</td>\n","      <td>80000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Vishal</td>\n","      <td>Singhal</td>\n","      <td>300000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>HR</td>\n","      <td>Lead</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Amitah</td>\n","      <td>Singh</td>\n","      <td>500000</td>\n","      <td>2014-02-20 9:00:00</td>\n","      <td>Admin</td>\n","      <td>Asst. Manager</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Vivek</td>\n","      <td>Bhati</td>\n","      <td>500000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Admin</td>\n","      <td>Manager</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Vipul</td>\n","      <td>Diwan</td>\n","      <td>200000</td>\n","      <td>2014-06-11 9:00:00</td>\n","      <td>Account</td>\n","      <td>Lead</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Satish</td>\n","      <td>Kumar</td>\n","      <td>75000</td>\n","      <td>2014-01-20 9:00:00</td>\n","      <td>Account</td>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Geetika</td>\n","      <td>Chauhan</td>\n","      <td>90000</td>\n","      <td>2014-04-11 9:00:00</td>\n","      <td>Admin</td>\n","      <td>Executive</td>\n","      <td>2016-06-11 0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name last_name  salary        joining_date department   worker_title  \\\n","1     Monika     Arora  100000  2014-02-20 9:00:00         HR        Manager   \n","2   Niharika     Verma   80000  2014-06-11 9:00:00      Admin      Executive   \n","3     Vishal   Singhal  300000  2014-02-20 9:00:00         HR           Lead   \n","4     Amitah     Singh  500000  2014-02-20 9:00:00      Admin  Asst. Manager   \n","5      Vivek     Bhati  500000  2014-06-11 9:00:00      Admin        Manager   \n","6      Vipul     Diwan  200000  2014-06-11 9:00:00    Account           Lead   \n","7     Satish     Kumar   75000  2014-01-20 9:00:00    Account      Executive   \n","8    Geetika   Chauhan   90000  2014-04-11 9:00:00      Admin      Executive   \n","\n","        affected_from  \n","1  2016-02-20 0:00:00  \n","2  2016-06-11 0:00:00  \n","3  2016-06-11 0:00:00  \n","4  2016-06-11 0:00:00  \n","5  2016-06-11 0:00:00  \n","6  2016-06-11 0:00:00  \n","7  2016-06-11 0:00:00  \n","8  2016-06-11 0:00:00  "]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"WsKwLpJVFL_P"},"source":["#### Merge the employee_group_indexed and employee_hire_date tables"]},{"cell_type":"code","metadata":{"id":"IebawnHkFL_P","outputId":"400ad4ec-2bb4-4522-c386-8be658ffca1b"},"source":["pd.merge(employee_group_indexed, employee_hire_date, left_index=True, right_on='employee')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>group</th>\n","      <th>employee</th>\n","      <th>hire_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Accounting</td>\n","      <td>Bob</td>\n","      <td>2008</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Engineering</td>\n","      <td>Jake</td>\n","      <td>2012</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Engineering</td>\n","      <td>Lisa</td>\n","      <td>2004</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>HR</td>\n","      <td>Sue</td>\n","      <td>2014</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         group employee  hire_date\n","1   Accounting      Bob       2008\n","2  Engineering     Jake       2012\n","0  Engineering     Lisa       2004\n","3           HR      Sue       2014"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"rlKh339aW1Am"},"source":["## Specifying Set Arithmetic for Joins"]},{"cell_type":"code","metadata":{"id":"HCxGwBFCW1An","outputId":"007562ad-88ce-470a-e68f-5bd82c9004cf"},"source":["food = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'],\n","                    'food': ['fish', 'beans', 'bread']},\n","                   columns=['name', 'food'])\n","drinks = pd.DataFrame({'name': ['Mary', 'Joseph'],\n","                    'drink': ['wine', 'beer']},\n","                   columns=['name', 'drink'])\n","\n","display('food', 'drinks')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>food</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>food</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Peter</td>\n","      <td>fish</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Paul</td>\n","      <td>beans</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mary</td>\n","      <td>bread</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>drinks</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>drink</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Mary</td>\n","      <td>wine</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Joseph</td>\n","      <td>beer</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["food\n","    name   food\n","0  Peter   fish\n","1   Paul  beans\n","2   Mary  bread\n","\n","drinks\n","     name drink\n","0    Mary  wine\n","1  Joseph  beer"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"O_u0OVcnFL_W"},"source":["#### What is the default join type when using the merge method? Add a 'how' parameter with the default join type"]},{"cell_type":"code","metadata":{"id":"eLwTuQFrFL_X","outputId":"3b48a259-ead2-453b-d0e2-44b4197de6ed"},"source":["pd.merge(food, drinks, how='inner')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>food</th>\n","      <th>drink</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Mary</td>\n","      <td>bread</td>\n","      <td>wine</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   name   food drink\n","0  Mary  bread  wine"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"uy8s487AFL_a"},"source":["#### Merge the food and drinks tables leaving all names from both tables in"]},{"cell_type":"code","metadata":{"id":"W7kOeH6_FL_a","outputId":"09f4f822-19f1-4a47-d3c6-f8b1bd96a4e6"},"source":["pd.merge(food, drinks, how='outer')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>food</th>\n","      <th>drink</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Peter</td>\n","      <td>fish</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Paul</td>\n","      <td>beans</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mary</td>\n","      <td>bread</td>\n","      <td>wine</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Joseph</td>\n","      <td>NaN</td>\n","      <td>beer</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     name   food drink\n","0   Peter   fish   NaN\n","1    Paul  beans   NaN\n","2    Mary  bread  wine\n","3  Joseph    NaN  beer"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"UyO_l8X-FL_c"},"source":["#### Merge food and drinks leaving only rows that have a defined food"]},{"cell_type":"code","metadata":{"id":"PFziXDByFL_d","outputId":"648803d9-e6a4-4560-bc3d-84e81730d5f2"},"source":["pd.merge(food, drinks, how='left')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>food</th>\n","      <th>drink</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Peter</td>\n","      <td>fish</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Paul</td>\n","      <td>beans</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mary</td>\n","      <td>bread</td>\n","      <td>wine</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    name   food drink\n","0  Peter   fish   NaN\n","1   Paul  beans   NaN\n","2   Mary  bread  wine"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"RG6D9fHrFL_e"},"source":["#### Merge food and drinks leaving only row that have a defined drink"]},{"cell_type":"code","metadata":{"id":"2qOqqFweFL_f","outputId":"27a8d08a-83fe-40ad-99a2-1ef3119156a0"},"source":["pd.merge(food, drinks, how='right')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>food</th>\n","      <th>drink</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Mary</td>\n","      <td>bread</td>\n","      <td>wine</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Joseph</td>\n","      <td>NaN</td>\n","      <td>beer</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     name   food drink\n","0    Mary  bread  wine\n","1  Joseph    NaN  beer"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"U7AnBlzpW1Ay"},"source":["## Overlapping Column Names: The ``suffixes`` Keyword"]},{"cell_type":"markdown","metadata":{"id":"u1SXwCCdW1Az"},"source":["Finally, you may end up in a case where your two input ``DataFrame``s have conflicting column names.\n","Consider this example:"]},{"cell_type":"code","metadata":{"id":"GHEp7e5PW1Az","outputId":"46a25882-7a4f-4c2a-cd95-95bf82b6491d"},"source":["df1 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n","                    'rank': [1, 2, 3, 4]})\n","df2 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n","                    'rank': [3, 1, 4, 2]})\n","display('df1', 'df2')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>df1</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>rank</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>df2</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>rank</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["df1\n","   name  rank\n","0   Bob     1\n","1  Jake     2\n","2  Lisa     3\n","3   Sue     4\n","\n","df2\n","   name  rank\n","0   Bob     3\n","1  Jake     1\n","2  Lisa     4\n","3   Sue     2"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"l2EXklX6FL_j"},"source":["#### Merge df1 and df2 on the name column using the default suffixes"]},{"cell_type":"code","metadata":{"id":"4hr01qEEFL_k","outputId":"099e5d07-43bf-4413-f4e1-a789a42d0d4e"},"source":["pd.merge(df1, df2, on='name')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>rank_x</th>\n","      <th>rank_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   name  rank_x  rank_y\n","0   Bob       1       3\n","1  Jake       2       1\n","2  Lisa       3       4\n","3   Sue       4       2"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"O4kQFHQVW1A2"},"source":["#### Merge df1 and df2 on the name column again, but this time define a set a suffixes for pandas to use"]},{"cell_type":"code","metadata":{"id":"euG_uwJrW1A2","outputId":"3a292bf2-15f4-4864-9d19-da5c5a24f556"},"source":["pd.merge(df1, df2, on=\"name\", suffixes=[\"_L\", \"_R\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>rank_L</th>\n","      <th>rank_R</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bob</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jake</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lisa</td>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sue</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   name  rank_L  rank_R\n","0   Bob       1       3\n","1  Jake       2       1\n","2  Lisa       3       4\n","3   Sue       4       2"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"NOfTzu_sW1A5"},"source":["## Example: US States Data"]},{"cell_type":"code","metadata":{"id":"jEjEXNCvW1A6","scrolled":true,"outputId":"e272dbf9-ceaa-41de-e7ed-55865ebeb894"},"source":["#import states_population.csv, states_areas.csv, states_abbrevs.csv from the link below\n","#https://bit.ly/3gsZdUS\n","\n","pop = pd.read_csv('states_population.csv')\n","areas = pd.read_csv('states_areas.csv')\n","abbrevs = pd.read_csv('states_abbrevs.csv')\n","\n","#display using code below\n","display('pop.head()', 'areas.head()', 'abbrevs.head()')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>pop.head()</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state_region</th>\n","      <th>ages</th>\n","      <th>year</th>\n","      <th>population</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2012</td>\n","      <td>1117489.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AL</td>\n","      <td>total</td>\n","      <td>2012</td>\n","      <td>4817528.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2010</td>\n","      <td>1130966.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AL</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>4785570.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2011</td>\n","      <td>1125763.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>areas.head()</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state</th>\n","      <th>area_sq_mile</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Alabama</td>\n","      <td>52423</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Alaska</td>\n","      <td>656425</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Arizona</td>\n","      <td>114006</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Arkansas</td>\n","      <td>53182</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>California</td>\n","      <td>163707</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>abbrevs.head()</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state</th>\n","      <th>abbreviation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Alabama</td>\n","      <td>AL</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Alaska</td>\n","      <td>AK</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Arizona</td>\n","      <td>AZ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Arkansas</td>\n","      <td>AR</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>California</td>\n","      <td>CA</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["pop.head()\n","  state_region     ages  year  population\n","0           AL  under18  2012   1117489.0\n","1           AL    total  2012   4817528.0\n","2           AL  under18  2010   1130966.0\n","3           AL    total  2010   4785570.0\n","4           AL  under18  2011   1125763.0\n","\n","areas.head()\n","        state  area_sq_mile\n","0     Alabama         52423\n","1      Alaska        656425\n","2     Arizona        114006\n","3    Arkansas         53182\n","4  California        163707\n","\n","abbrevs.head()\n","        state abbreviation\n","0     Alabama           AL\n","1      Alaska           AK\n","2     Arizona           AZ\n","3    Arkansas           AR\n","4  California           CA"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"Yy6LFRB-FL_p"},"source":["### We'll be using merges and joins to calculate statistics about state population. Our ultimate goal is to calculate the state with the largest population density in 2010"]},{"cell_type":"markdown","metadata":{"id":"UFeHElu4FL_p"},"source":["#### First, we need to merge our tables together. Merge the pop and abbrevs tables. Drop the redundant abbreviation column"]},{"cell_type":"code","metadata":{"id":"Zg1kaQvkW1A-","outputId":"383ba506-ae5e-4dd1-f7fc-f9e01c03b44f"},"source":["merged = pd.merge(pop, abbrevs, how='outer', left_on='state_region', right_on='abbreviation')\n","merged = merged.drop('abbreviation', 1)\n","merged.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state_region</th>\n","      <th>ages</th>\n","      <th>year</th>\n","      <th>population</th>\n","      <th>state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2012</td>\n","      <td>1117489.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AL</td>\n","      <td>total</td>\n","      <td>2012</td>\n","      <td>4817528.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2010</td>\n","      <td>1130966.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AL</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>4785570.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2011</td>\n","      <td>1125763.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  state_region     ages  year  population    state\n","0           AL  under18  2012   1117489.0  Alabama\n","1           AL    total  2012   4817528.0  Alabama\n","2           AL  under18  2010   1130966.0  Alabama\n","3           AL    total  2010   4785570.0  Alabama\n","4           AL  under18  2011   1125763.0  Alabama"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"k6SDDJ7oW1BA"},"source":["#### It's important to check if the data is valid. Check if there are any nulls in the table"]},{"cell_type":"code","metadata":{"id":"NOjana5eW1BB","outputId":"58c378b2-5f0e-4fe0-d4b6-4eab261b1033"},"source":["merged.isnull().any()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["state_region    False\n","ages            False\n","year            False\n","population       True\n","state            True\n","dtype: bool"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"2mU2821aW1BD"},"source":["#### As you can see, there are null values for population and state. Display a table filtered for rows with a null state and one for rows with a null population. Figure out what is wrong with the data using the displayed tables"]},{"cell_type":"code","metadata":{"id":"EBW1cWR4W1BD","scrolled":true,"outputId":"4ebde8ec-1f3d-4c73-9060-b68adde7b956"},"source":["display(\"merged[merged['state'].isnull()]\", \"merged[merged['population'].isnull()]\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>merged[merged['state'].isnull()]</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state_region</th>\n","      <th>ages</th>\n","      <th>year</th>\n","      <th>population</th>\n","      <th>state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2448</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1990</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2449</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1990</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2450</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1991</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2451</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1991</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2452</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1993</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2453</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1993</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2454</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1992</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2455</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1992</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2456</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1994</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2457</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1994</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2458</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1995</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2459</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1995</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2460</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1996</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2461</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1996</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2462</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1998</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2463</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1998</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2464</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1997</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2465</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1997</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2466</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1999</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2467</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1999</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2468</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>2000</td>\n","      <td>3810605.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2469</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>2000</td>\n","      <td>1089063.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2470</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>2001</td>\n","      <td>3818774.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2471</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>2001</td>\n","      <td>1077566.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2472</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>2002</td>\n","      <td>3823701.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2473</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>2002</td>\n","      <td>1065051.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2474</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>2004</td>\n","      <td>3826878.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2475</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>2004</td>\n","      <td>1035919.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2476</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>2003</td>\n","      <td>3826095.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2477</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>2003</td>\n","      <td>1050615.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2514</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>1999</td>\n","      <td>71946051.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2515</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2000</td>\n","      <td>282162411.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2516</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2000</td>\n","      <td>72376189.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2517</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>1999</td>\n","      <td>279040181.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2518</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2001</td>\n","      <td>284968955.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2519</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2001</td>\n","      <td>72671175.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2520</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2002</td>\n","      <td>287625193.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2521</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2002</td>\n","      <td>72936457.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2522</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2003</td>\n","      <td>290107933.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2523</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2003</td>\n","      <td>73100758.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2524</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2004</td>\n","      <td>292805298.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2525</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2004</td>\n","      <td>73297735.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2526</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2005</td>\n","      <td>295516599.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2527</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2005</td>\n","      <td>73523669.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2528</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2006</td>\n","      <td>298379912.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2529</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2006</td>\n","      <td>73757714.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2530</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2007</td>\n","      <td>301231207.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2531</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2007</td>\n","      <td>74019405.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2532</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2008</td>\n","      <td>304093966.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2533</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2008</td>\n","      <td>74104602.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2534</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2013</td>\n","      <td>73585872.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2535</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2013</td>\n","      <td>316128839.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2536</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2009</td>\n","      <td>306771529.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2537</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2009</td>\n","      <td>74134167.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2538</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2010</td>\n","      <td>74119556.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2539</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>309326295.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2540</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2011</td>\n","      <td>73902222.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2541</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2011</td>\n","      <td>311582564.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2542</th>\n","      <td>USA</td>\n","      <td>under18</td>\n","      <td>2012</td>\n","      <td>73708179.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2543</th>\n","      <td>USA</td>\n","      <td>total</td>\n","      <td>2012</td>\n","      <td>313873685.0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>96 rows  5 columns</p>\n","</div>\n","    </div>\n","<div style=\"float: left; padding: 10px;\">\n","    <p style='font-family:\"Courier New\", Courier, monospace'>merged[merged['population'].isnull()]</p><div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state_region</th>\n","      <th>ages</th>\n","      <th>year</th>\n","      <th>population</th>\n","      <th>state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2448</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1990</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2449</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1990</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2450</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1991</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2451</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1991</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2452</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1993</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2453</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1993</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2454</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1992</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2455</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1992</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2456</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1994</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2457</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1994</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2458</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1995</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2459</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1995</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2460</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1996</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2461</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1996</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2462</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1998</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2463</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1998</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2464</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1997</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2465</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1997</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2466</th>\n","      <td>PR</td>\n","      <td>total</td>\n","      <td>1999</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2467</th>\n","      <td>PR</td>\n","      <td>under18</td>\n","      <td>1999</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    </div>"],"text/plain":["merged[merged['state'].isnull()]\n","     state_region     ages  year   population state\n","2448           PR  under18  1990          NaN   NaN\n","2449           PR    total  1990          NaN   NaN\n","2450           PR    total  1991          NaN   NaN\n","2451           PR  under18  1991          NaN   NaN\n","2452           PR    total  1993          NaN   NaN\n","2453           PR  under18  1993          NaN   NaN\n","2454           PR  under18  1992          NaN   NaN\n","2455           PR    total  1992          NaN   NaN\n","2456           PR  under18  1994          NaN   NaN\n","2457           PR    total  1994          NaN   NaN\n","2458           PR    total  1995          NaN   NaN\n","2459           PR  under18  1995          NaN   NaN\n","2460           PR  under18  1996          NaN   NaN\n","2461           PR    total  1996          NaN   NaN\n","2462           PR  under18  1998          NaN   NaN\n","2463           PR    total  1998          NaN   NaN\n","2464           PR    total  1997          NaN   NaN\n","2465           PR  under18  1997          NaN   NaN\n","2466           PR    total  1999          NaN   NaN\n","2467           PR  under18  1999          NaN   NaN\n","2468           PR    total  2000    3810605.0   NaN\n","2469           PR  under18  2000    1089063.0   NaN\n","2470           PR    total  2001    3818774.0   NaN\n","2471           PR  under18  2001    1077566.0   NaN\n","2472           PR    total  2002    3823701.0   NaN\n","2473           PR  under18  2002    1065051.0   NaN\n","2474           PR    total  2004    3826878.0   NaN\n","2475           PR  under18  2004    1035919.0   NaN\n","2476           PR    total  2003    3826095.0   NaN\n","2477           PR  under18  2003    1050615.0   NaN\n","...           ...      ...   ...          ...   ...\n","2514          USA  under18  1999   71946051.0   NaN\n","2515          USA    total  2000  282162411.0   NaN\n","2516          USA  under18  2000   72376189.0   NaN\n","2517          USA    total  1999  279040181.0   NaN\n","2518          USA    total  2001  284968955.0   NaN\n","2519          USA  under18  2001   72671175.0   NaN\n","2520          USA    total  2002  287625193.0   NaN\n","2521          USA  under18  2002   72936457.0   NaN\n","2522          USA    total  2003  290107933.0   NaN\n","2523          USA  under18  2003   73100758.0   NaN\n","2524          USA    total  2004  292805298.0   NaN\n","2525          USA  under18  2004   73297735.0   NaN\n","2526          USA    total  2005  295516599.0   NaN\n","2527          USA  under18  2005   73523669.0   NaN\n","2528          USA    total  2006  298379912.0   NaN\n","2529          USA  under18  2006   73757714.0   NaN\n","2530          USA    total  2007  301231207.0   NaN\n","2531          USA  under18  2007   74019405.0   NaN\n","2532          USA    total  2008  304093966.0   NaN\n","2533          USA  under18  2008   74104602.0   NaN\n","2534          USA  under18  2013   73585872.0   NaN\n","2535          USA    total  2013  316128839.0   NaN\n","2536          USA    total  2009  306771529.0   NaN\n","2537          USA  under18  2009   74134167.0   NaN\n","2538          USA  under18  2010   74119556.0   NaN\n","2539          USA    total  2010  309326295.0   NaN\n","2540          USA  under18  2011   73902222.0   NaN\n","2541          USA    total  2011  311582564.0   NaN\n","2542          USA  under18  2012   73708179.0   NaN\n","2543          USA    total  2012  313873685.0   NaN\n","\n","[96 rows x 5 columns]\n","\n","merged[merged['population'].isnull()]\n","     state_region     ages  year  population state\n","2448           PR  under18  1990         NaN   NaN\n","2449           PR    total  1990         NaN   NaN\n","2450           PR    total  1991         NaN   NaN\n","2451           PR  under18  1991         NaN   NaN\n","2452           PR    total  1993         NaN   NaN\n","2453           PR  under18  1993         NaN   NaN\n","2454           PR  under18  1992         NaN   NaN\n","2455           PR    total  1992         NaN   NaN\n","2456           PR  under18  1994         NaN   NaN\n","2457           PR    total  1994         NaN   NaN\n","2458           PR    total  1995         NaN   NaN\n","2459           PR  under18  1995         NaN   NaN\n","2460           PR  under18  1996         NaN   NaN\n","2461           PR    total  1996         NaN   NaN\n","2462           PR  under18  1998         NaN   NaN\n","2463           PR    total  1998         NaN   NaN\n","2464           PR    total  1997         NaN   NaN\n","2465           PR  under18  1997         NaN   NaN\n","2466           PR    total  1999         NaN   NaN\n","2467           PR  under18  1999         NaN   NaN"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"2euWmq1oFL_v"},"source":["#### The issues are that Puerto Rico and the entire USA area do not exist in the abbrev table and Puerto Rico lacks population data before 2000. In this case, we will drop the missing data because we only care about states. Drop any null rows from merged"]},{"cell_type":"code","metadata":{"id":"zDZYkxaCFL_v","outputId":"0fc0dcb1-7097-4c2f-d5ef-45b42fa963ea"},"source":["merged = merged.dropna()\n","merged.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state_region</th>\n","      <th>ages</th>\n","      <th>year</th>\n","      <th>population</th>\n","      <th>state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2012</td>\n","      <td>1117489.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AL</td>\n","      <td>total</td>\n","      <td>2012</td>\n","      <td>4817528.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2010</td>\n","      <td>1130966.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AL</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>4785570.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2011</td>\n","      <td>1125763.0</td>\n","      <td>Alabama</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  state_region     ages  year  population    state\n","0           AL  under18  2012   1117489.0  Alabama\n","1           AL    total  2012   4817528.0  Alabama\n","2           AL  under18  2010   1130966.0  Alabama\n","3           AL    total  2010   4785570.0  Alabama\n","4           AL  under18  2011   1125763.0  Alabama"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"0QvVHTRnFL_x"},"source":["#### Now you can continue merging tables. Merge the merged and areas tables and store the results in final"]},{"cell_type":"code","metadata":{"id":"-N-dAZHQFL_y","outputId":"a8b7d793-9721-437c-e3e9-ef30964b3208"},"source":["final = pd.merge(merged, areas, on=\"state\")\n","final.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state_region</th>\n","      <th>ages</th>\n","      <th>year</th>\n","      <th>population</th>\n","      <th>state</th>\n","      <th>area_sq_mile</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2012</td>\n","      <td>1117489.0</td>\n","      <td>Alabama</td>\n","      <td>52423</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AL</td>\n","      <td>total</td>\n","      <td>2012</td>\n","      <td>4817528.0</td>\n","      <td>Alabama</td>\n","      <td>52423</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2010</td>\n","      <td>1130966.0</td>\n","      <td>Alabama</td>\n","      <td>52423</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AL</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>4785570.0</td>\n","      <td>Alabama</td>\n","      <td>52423</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AL</td>\n","      <td>under18</td>\n","      <td>2011</td>\n","      <td>1125763.0</td>\n","      <td>Alabama</td>\n","      <td>52423</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  state_region     ages  year  population    state  area_sq_mile\n","0           AL  under18  2012   1117489.0  Alabama         52423\n","1           AL    total  2012   4817528.0  Alabama         52423\n","2           AL  under18  2010   1130966.0  Alabama         52423\n","3           AL    total  2010   4785570.0  Alabama         52423\n","4           AL  under18  2011   1125763.0  Alabama         52423"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"jdrqA690FL_0"},"source":["#### Check for nulls in the resulting table"]},{"cell_type":"code","metadata":{"id":"9UTH3_c7FL_2","outputId":"9158cedf-635f-42ca-bb3c-ad09f6827b5e"},"source":["final.isnull().any()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["state_region    False\n","ages            False\n","year            False\n","population      False\n","state           False\n","area_sq_mile    False\n","dtype: bool"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"qjU3CiCsFL_4"},"source":["#### The final table contains no nulls so you can continue. Filter the final table for rows where ages is total and year is 2010. You may use the query method. Store the result in pop_2010 and set the index to state"]},{"cell_type":"code","metadata":{"id":"tm_tZqkKFL_4","outputId":"26d09e92-f78f-4cd0-9dce-9132ad5381a6"},"source":["pop_2010 = final.query(\"ages == 'total' & year == 2010\")\n","pop_2010.set_index('state', inplace=True)\n","pop_2010.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state_region</th>\n","      <th>ages</th>\n","      <th>year</th>\n","      <th>population</th>\n","      <th>area_sq_mile</th>\n","    </tr>\n","    <tr>\n","      <th>state</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Alabama</th>\n","      <td>AL</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>4785570.0</td>\n","      <td>52423</td>\n","    </tr>\n","    <tr>\n","      <th>Alaska</th>\n","      <td>AK</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>713868.0</td>\n","      <td>656425</td>\n","    </tr>\n","    <tr>\n","      <th>Arizona</th>\n","      <td>AZ</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>6408790.0</td>\n","      <td>114006</td>\n","    </tr>\n","    <tr>\n","      <th>Arkansas</th>\n","      <td>AR</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>2922280.0</td>\n","      <td>53182</td>\n","    </tr>\n","    <tr>\n","      <th>California</th>\n","      <td>CA</td>\n","      <td>total</td>\n","      <td>2010</td>\n","      <td>37333601.0</td>\n","      <td>163707</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           state_region   ages  year  population  area_sq_mile\n","state                                                         \n","Alabama              AL  total  2010   4785570.0         52423\n","Alaska               AK  total  2010    713868.0        656425\n","Arizona              AZ  total  2010   6408790.0        114006\n","Arkansas             AR  total  2010   2922280.0         53182\n","California           CA  total  2010  37333601.0        163707"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"markdown","metadata":{"id":"asuvCTBxFL_5"},"source":["#### Now you can calculate the final result. Calculate and create a series 'density' from the columns of pop_2010. Then, sort the values of this series. Print the final result"]},{"cell_type":"code","metadata":{"id":"rMD0DBssFL_6","outputId":"4cbb579c-7dbc-4a82-d8e3-41632e35ea4b"},"source":["density = pop_2010['population'] / pop_2010['area_sq_mile']\n","density.sort_values(ascending=False, inplace=True)\n","density"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["state\n","District of Columbia    8898.897059\n","New Jersey              1009.253268\n","Rhode Island             681.339159\n","Connecticut              645.600649\n","Massachusetts            621.815538\n","Maryland                 466.445797\n","Delaware                 460.445752\n","New York                 356.094135\n","Florida                  286.597129\n","Pennsylvania             275.966651\n","Ohio                     257.549634\n","California               228.051342\n","Illinois                 221.687472\n","Virginia                 187.622273\n","Indiana                  178.197831\n","North Carolina           177.617157\n","Georgia                  163.409902\n","Tennessee                150.825298\n","South Carolina           144.854594\n","New Hampshire            140.799273\n","Hawaii                   124.746707\n","Kentucky                 107.586994\n","Michigan                 102.015794\n","Washington                94.557817\n","Texas                     93.987655\n","Alabama                   91.287603\n","Louisiana                 87.676099\n","Wisconsin                 86.851900\n","Missouri                  86.015622\n","West Virginia             76.519582\n","Vermont                   65.085075\n","Mississippi               61.321530\n","Minnesota                 61.078373\n","Arizona                   56.214497\n","Arkansas                  54.948667\n","Iowa                      54.202751\n","Oklahoma                  53.778278\n","Colorado                  48.493718\n","Oregon                    39.001565\n","Maine                     37.509990\n","Kansas                    34.745266\n","Utah                      32.677188\n","Nevada                    24.448796\n","Nebraska                  23.654153\n","Idaho                     18.794338\n","New Mexico                16.982737\n","South Dakota              10.583512\n","North Dakota               9.537565\n","Montana                    6.736171\n","Wyoming                    5.768079\n","Alaska                     1.087509\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":54}]}]}